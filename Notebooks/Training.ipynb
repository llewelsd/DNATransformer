{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T09:49:59.805629Z",
     "start_time": "2020-12-21T09:49:56.546796Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import time\n",
    "import pickle\n",
    "from transformers import Trainer,TrainingArguments,BartConfig,BartTokenizer,BartModel,BartForConditionalGeneration,BartTokenizerFast\n",
    "from torch.utils import data as data_utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"big_data\" contains precomputed simulations for 198 length sequences.\n",
    "\n",
    "Do not recommend for CPU systems, or if you want to do this quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T09:54:05.406893Z",
     "start_time": "2020-12-21T09:54:05.403980Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"../DataSets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T09:49:49.447697Z",
     "start_time": "2020-12-21T09:49:49.444768Z"
    }
   },
   "outputs": [],
   "source": [
    "big_data = data_dir+\"dna_big_sim_output.txt\"\n",
    "big_data_header = [\"dna\",\"length\",\"energy\",\"struct\",\"blank\",\"prob\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"small_data\" is only of length 32, with fewer sequences and is more managable\n",
    "\n",
    "Future work will be on a more flexible model that can handle variable lengths, but current intended use is only on sequences of a known set length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T09:54:08.491225Z",
     "start_time": "2020-12-21T09:54:08.488296Z"
    }
   },
   "outputs": [],
   "source": [
    "small_data = data_dir+\"dna_small_sim_output.txt\"\n",
    "small_data_header = [\"dna\",\"length\",\"energy\",\"struct\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load prefered data set into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T09:54:11.704573Z",
     "start_time": "2020-12-21T09:54:11.373525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "header_names = small_data_header\n",
    "data = pd.read_csv(small_data,sep=\"\\\\t\",header=None,names=header_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break the DNA and structure up for the tokenizer \n",
    "\n",
    "This is because the tokenizer expects to see words, not individual characters \n",
    "\n",
    "(it was made originally for NLP)\n",
    "\n",
    "(building custom tokenizer may be possible, but model was prebuilt to be used with this tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:35:07.567839Z",
     "start_time": "2020-12-21T04:35:07.413542Z"
    }
   },
   "outputs": [],
   "source": [
    "dna = data[\"dna\"]\n",
    "struct = data[\"struct\"]\n",
    "\n",
    "dna_list = [\" \".join(list(d)) for d in data[\"dna\"]]\n",
    "struct_list = [\" \".join(list(s)) for s in data[\"struct\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set into a train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(dna) # total number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:39:22.489767Z",
     "start_time": "2020-12-21T04:39:22.486837Z"
    }
   },
   "outputs": [],
   "source": [
    "# run this block for an easier, shorter run\n",
    "length = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:40:30.893568Z",
     "start_time": "2020-12-21T04:40:30.889663Z"
    }
   },
   "outputs": [],
   "source": [
    "split = int(length * 0.75) # default for this is 75/25 train-val.\n",
    "\n",
    "dna_train = dna_list[:split]\n",
    "dna_val = dna_list[split:]\n",
    "\n",
    "struct_train = struct_list[:split]\n",
    "struct_val = struct_list[split:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a prebuilt tokenizer that is known to work with this model\n",
    "\n",
    "NOTE: may take a while on first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:28:25.697474Z",
     "start_time": "2020-12-21T04:28:23.587529Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizerFast.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:42:32.984008Z",
     "start_time": "2020-12-21T04:42:32.661465Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_train = tokenizer.prepare_seq2seq_batch(src_texts = dna_train, \n",
    "                                                  tgt_texts = struct_train,\n",
    "                                                  padding=True,\n",
    "                                                  return_tensors='pt',\n",
    "                                                  truncation=True,\n",
    "                                                  #return_token_type_ids = True,\n",
    "                                                  max_length=202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:42:32.660489Z",
     "start_time": "2020-12-21T04:42:28.446974Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_val = tokenizer.prepare_seq2seq_batch(src_texts = dna_val, \n",
    "                                                tgt_texts = struct_val,\n",
    "                                                padding=True,\n",
    "                                                return_tensors='pt',\n",
    "                                                truncation=True,\n",
    "                                                #return_token_type_ids = True,\n",
    "                                                max_length=202)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom dataset class because pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:43:18.311654Z",
     "start_time": "2020-12-21T04:43:18.307748Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(data_utils.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # self.encodings.keys() = ['input_ids', 'attention_mask', 'start_positions', 'end_positions']\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pyTorch Datasets for training (tds) and evalidation (eds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:44:00.268240Z",
     "start_time": "2020-12-21T04:44:00.265310Z"
    }
   },
   "outputs": [],
   "source": [
    "tds = MyDataset(tokenized_train)\n",
    "eds = MyDataset(tokenized_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments for the trainer\n",
    "\n",
    "Training can take a while before a good result is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T08:52:55.088654Z",
     "start_time": "2020-12-21T08:52:55.084748Z"
    }
   },
   "outputs": [],
   "source": [
    "small_training_args = TrainingArguments(\n",
    "    output_dir = \"./BART_Small_Output\", # where to store the checkpoints\n",
    "    logging_dir = \"./BART_Small_log\", # logging directory\n",
    "    per_device_train_batch_size=256,  # batch size per device during training NOTE: if on CPU or if you get OOM errors, set to smaller number\n",
    "    per_device_eval_batch_size=256,   # batch size for evaluation NOTE: if on CPU or if you get OOM errors, set to smaller number\n",
    "    fp16 = True, # if having NAN errors, disable. keeping true helps run faster\n",
    "    num_train_epochs=100) # number of training epochs to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_training_args = TrainingArguments(\n",
    "    output_dir = \"./BART_Big_Output\", # where to store the checkpoints\n",
    "    logging_dir = \"./BART_Big_log\", # logging directory\n",
    "    per_device_train_batch_size=64,  # batch size per device during training NOTE: if on CPU or if you get OOM errors, set to smaller number\n",
    "    per_device_eval_batch_size=63,   # batch size for evaluation NOTE: if on CPU or if you get OOM errors, set to smaller number\n",
    "    fp16 = True, # if having NAN errors, disable. keeping true helps run faster\n",
    "    num_train_epochs=100) # number of training epochs to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure and create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T08:52:57.251697Z",
     "start_time": "2020-12-21T08:52:56.781003Z"
    }
   },
   "outputs": [],
   "source": [
    "config = BartConfig(\n",
    "    d_model = 256,\n",
    "    encoder_layers=6,\n",
    "    decoder_layers=6,\n",
    "    encoder_attention_heads=8,\n",
    "    decoder_attention_heads=8,\n",
    "    decoder_ffn_dim=1024,\n",
    "    encoder_ffn_dim=1024\n",
    "    )\n",
    "model = BartForConditionalGeneration (config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncommont and fill in URI for a previous training checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:45:22.334719Z",
     "start_time": "2020-12-21T04:45:22.331789Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = BartForConditionalGeneration.from_pretrained('.\\<Path To Model>', return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the trainer from previous arguments and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T08:52:59.341503Z",
     "start_time": "2020-12-21T08:52:59.308300Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model = model, \n",
    "                         args = small_training_args, \n",
    "                         train_dataset =tds,\n",
    "                         eval_dataset = eds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the trainer\n",
    "\n",
    "It will create checkpoints every 500 steps\n",
    "\n",
    "(recommend to clean out checkpoints, they can take up a lot of space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T09:00:39.408744Z",
     "start_time": "2020-12-21T08:53:01.682387Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 07:37, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.373527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.336531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.307887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.297448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.291894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.288438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=0.6492874348958333)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T09:07:01.865673Z",
     "start_time": "2020-12-21T09:07:01.648882Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('DNA_BART_32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-20T21:38:40.272621Z",
     "start_time": "2020-12-20T21:38:40.264613Z"
    }
   },
   "source": [
    "Open the testing notebook to try out your model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
