{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Import Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:31:07.395758Z",
     "start_time": "2020-12-21T04:31:07.391852Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import time\n",
    "import pickle\n",
    "from transformers import Trainer,TrainingArguments,BartConfig,BartTokenizer,BartModel,BartForConditionalGeneration,BartTokenizerFast\n",
    "from torch.utils import data as data_utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"big_data\" contains precomputed simulations for 198 length sequences.\n",
    "\n",
    "Do no recommend for CPU systems, or if you want to do this quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:29:06.565627Z",
     "start_time": "2020-12-21T04:29:06.562697Z"
    }
   },
   "outputs": [],
   "source": [
    "big_data = \"NP_sim_output198_1000000.txt\"\n",
    "big_data_header = [\"dna\",\"length\",\"energy\",\"struct\",\"blank\",\"prob\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"small_data\" is only of length 32, with fewer sequences and is more managable\n",
    "\n",
    "Future work will be on a more flexible model that can handle variable lengths, but current intended use is only on sequences of a known set length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:29:07.504020Z",
     "start_time": "2020-12-21T04:29:07.501090Z"
    }
   },
   "outputs": [],
   "source": [
    "small_data = \"dna_small_sim_output.txt\"\n",
    "small_data_header = [\"dna\",\"length\",\"energy\",\"struct\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load prefered data set into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:29:09.979828Z",
     "start_time": "2020-12-21T04:29:09.649590Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "header_names = small_data_header\n",
    "data = pd.read_csv(small_data,sep=\"\\\\t\",header=None,names=header_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break the DNA and structure up for the tokenizer \n",
    "\n",
    "This is because the tokenizer expects to see words, not individual characters \n",
    "\n",
    "(it was made originally for NLP)\n",
    "\n",
    "(building custom tokenizer may be possible, but model was prebuilt to be used with this tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:35:07.567839Z",
     "start_time": "2020-12-21T04:35:07.413542Z"
    }
   },
   "outputs": [],
   "source": [
    "dna = data[\"dna\"]\n",
    "struct = data[\"struct\"]\n",
    "\n",
    "dna_list = [\" \".join(list(d)) for d in data[\"dna\"]]\n",
    "struct_list = [\" \".join(list(s)) for s in data[\"struct\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set into a train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(dna) # total number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:39:22.489767Z",
     "start_time": "2020-12-21T04:39:22.486837Z"
    }
   },
   "outputs": [],
   "source": [
    "# run this block for an easier, shorter run\n",
    "length = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:40:30.893568Z",
     "start_time": "2020-12-21T04:40:30.889663Z"
    }
   },
   "outputs": [],
   "source": [
    "split = int(length * 0.75) # default for this is 75/25 train-val.\n",
    "\n",
    "dna_train = dna_list[:split]\n",
    "dna_val = dna_list[split:]\n",
    "\n",
    "struct_train = struct_list[:split]\n",
    "struct_val = struct_list[split:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a prebuilt tokenizer that is known to work with this model\n",
    "\n",
    "NOTE: may take a while on first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:28:25.697474Z",
     "start_time": "2020-12-21T04:28:23.587529Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizerFast.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:42:32.984008Z",
     "start_time": "2020-12-21T04:42:32.661465Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_train = tokenizer.prepare_seq2seq_batch(src_texts = dna_train, \n",
    "                                                  tgt_texts = struct_train,\n",
    "                                                  padding=True,\n",
    "                                                  return_tensors='pt',\n",
    "                                                  truncation=True,\n",
    "                                                  #return_token_type_ids = True,\n",
    "                                                  max_length=202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:42:32.660489Z",
     "start_time": "2020-12-21T04:42:28.446974Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_val = tokenizer.prepare_seq2seq_batch(src_texts = dna_val, \n",
    "                                                tgt_texts = struct_val,\n",
    "                                                padding=True,\n",
    "                                                return_tensors='pt',\n",
    "                                                truncation=True,\n",
    "                                                #return_token_type_ids = True,\n",
    "                                                max_length=202)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom dataset class because pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:43:18.311654Z",
     "start_time": "2020-12-21T04:43:18.307748Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(data_utils.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # self.encodings.keys() = ['input_ids', 'attention_mask', 'start_positions', 'end_positions']\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pyTorch Datasets for training (tds) and evalidation (eds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:44:00.268240Z",
     "start_time": "2020-12-21T04:44:00.265310Z"
    }
   },
   "outputs": [],
   "source": [
    "tds = MyDataset(tokenized_train)\n",
    "eds = MyDataset(tokenized_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments for the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:51:54.795108Z",
     "start_time": "2020-12-21T04:51:54.791202Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./BART_Small_Output\", # where to store the checkpoints\n",
    "    logging_dir = \"./BART_Small_log\", # logging directory\n",
    "    per_device_train_batch_size=64,  # batch size per device during training NOTE: if on CPU or if you get OOM errors, set to smaller number\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation NOTE: if on CPU or if you get OOM errors, set to smaller number\n",
    "    fp16 = True, # if having NAN errors, disable. keeping true helps run faster\n",
    "    num_train_epochs=10) # number of training epochs to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure and create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:48:52.000793Z",
     "start_time": "2020-12-21T04:48:51.558011Z"
    }
   },
   "outputs": [],
   "source": [
    "config = BartConfig(\n",
    "    d_model = 256,\n",
    "    encoder_layers=6,\n",
    "    decoder_layers=6,\n",
    "    encoder_attention_heads=8,\n",
    "    decoder_attention_heads=8,\n",
    "    decoder_ffn_dim=1024,\n",
    "    encoder_ffn_dim=1024\n",
    "    )\n",
    "model = BartForConditionalGeneration (config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncommont and fill in URI for a previous training checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:45:22.334719Z",
     "start_time": "2020-12-21T04:45:22.331789Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = BartForConditionalGeneration.from_pretrained('.\\<Path To Model>', return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the trainer from previous arguments and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:51:57.258149Z",
     "start_time": "2020-12-21T04:51:57.250831Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model = model, \n",
    "                         args = training_args, \n",
    "                         train_dataset =tds,\n",
    "                         eval_dataset = eds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:53:51.627302Z",
     "start_time": "2020-12-21T04:52:02.777911Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1180' max='1180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1180/1180 01:48, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.489514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.364157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "C:\\Users\\Shoshi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1180, training_loss=1.261438298629502)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T04:54:25.377407Z",
     "start_time": "2020-12-21T04:54:25.170380Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('DNA_BART_32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-20T21:38:40.272621Z",
     "start_time": "2020-12-20T21:38:40.264613Z"
    }
   },
   "source": [
    "Open the testing notebook to try out your model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
